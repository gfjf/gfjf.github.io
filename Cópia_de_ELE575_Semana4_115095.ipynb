{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gfjf/gfjf.github.io/blob/main/C%C3%B3pia_de_ELE575_Semana4_115095.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Aprendizado Profundo\n",
        "##Atividade Prática 3\n"
      ],
      "metadata": {
        "id": "vlJ8if4OVMXG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplique a técnica de transfer learning para treinar um novo modelo para classificar o dataset CIFAR-10, usado na Atividade 2.\n",
        "\n",
        "Comente sobre os resultados obtidos neste experimento quando comparados com os resultados obtidos na realização da Atividade 2.\n",
        "\n",
        "Foi mais fácil e rápido treinar o modelo usando transfer learning?\n",
        "\n"
      ],
      "metadata": {
        "id": "09UsqY29OXL6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Carregamos as bibliotecas"
      ],
      "metadata": {
        "id": "ZrD2ZDL7VXPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.ndimage\n",
        "import os\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Lambda, Input\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n"
      ],
      "metadata": {
        "id": "mepYIv5SXA6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Carregamos o dataset"
      ],
      "metadata": {
        "id": "D2WVw2iJ-iPf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usaremos o dataset CIFAR-10 (https://www.cs.toronto.edu/~kriz/cifar.htm), que consiste em 60.000 imagens coloridas de 32x32x3 (32x32 pixels, com 3 canais de cores RGB), distribuídas uniformemente em 10 classes. Existem 50.000 imagens de treinamento e 10.000 imagens de teste.\n",
        "\n",
        "O conjunto de dados é dividido em cinco lotes de treinamento e um lote de teste, cada um com 10.000 imagens. O lote de teste contém exatamente 1.000 imagens selecionadas aleatoriamente de cada classe. Os lotes de treinamento contêm as imagens restantes em ordem aleatória, mas alguns lotes de treinamento podem conter mais de uma classe do que de outra. Entre eles, os lotes de treinamento contêm exatamente 5.000 imagens de cada classe.\n",
        "\n",
        "*Referência*: Aprendendo várias camadas de recursos de imagens minúsculas, Alex Krizhevsky, 2009.\n",
        "\n",
        "* Usaremos a versão disponível no tensorflow.\n"
      ],
      "metadata": {
        "id": "rxJzwLQB-leO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# carregamos o dataset\n",
        "(trainX, trainY), (testX, testY) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "0oTJGJS7_oQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train samples:\", trainX.shape, trainY.shape)\n",
        "print(\"Test samples:\", testX.shape, testY.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzDAcPYW1Js8",
        "outputId": "92d3cabd-090f-4a05-8e5b-7d27b73de86f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: (50000, 32, 32, 3) (50000, 1)\n",
            "Test samples: (10000, 32, 32, 3) (10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 10\n",
        "cifar10_classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
        "                   \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
      ],
      "metadata": {
        "id": "tiFaTOgM3jDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preparação dos dados de entrada"
      ],
      "metadata": {
        "id": "2E5Tclci4KB6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reformatação**\n",
        "\n",
        "Redefinimos o formato das imagens do dataset, tanto a base de treino como a base de teste, para o mínimo aceito pelo VGG16: 48x48x3.\n",
        "\n",
        "**Normalização**\n",
        "\n",
        "Normalizamos os dados de entrada com a função:\n",
        "$$x_{norm} = \\frac{x}{255}$$\n",
        "\n",
        "Também transformamos de classe da variável alvo em um vetor de codificação one-hot."
      ],
      "metadata": {
        "id": "OnIgJaRcX-oH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertemos os valores dos pixels em float\n",
        "trainX = trainX.astype('float32')\n",
        "testX = testX.astype('float32')\n",
        "\n",
        "#input_shape = (48, 48, 3)\n",
        "\n",
        "# normalizamos para escala [0-1]\n",
        "X_train = (trainX / 255)\n",
        "X_test = (testX / 255)\n",
        "\n",
        "# resize train set\n",
        "#X_train = []\n",
        "#for img in trainX:\n",
        " # X_train.append(np.resize(img, input_shape) / 255)\n",
        "\n",
        "#X_train = np.array(X_train)\n",
        "#print(X_train.shape)\n",
        "\n",
        "# resize test set\n",
        "#X_test = []\n",
        "#for img in testX:\n",
        " # X_test.append(np.resize(img, input_shape) / 255)\n",
        "\n",
        "#X_test = np.array(X_test)\n",
        "#print(X_test.shape)\n",
        "\n",
        "# convertemos os rótulos ou variável alvo\n",
        "Y_train = to_categorical(trainY, NUM_CLASSES)\n",
        "Y_test = to_categorical(testY, NUM_CLASSES)"
      ],
      "metadata": {
        "id": "6sdeuEG4zNqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construção do modelo"
      ],
      "metadata": {
        "id": "4yIlMtBSYkCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Aqui construíremos nosso modelo. Usaremos como base o modelo VGG16 pré-treinado com o conjunto de dados ImageNet.\n",
        "\n",
        "A ideia do Transfer Learning é usar o modelo pré-treinado para extrair algumas características dos nossos dados. Essas extração de características foi previamente aprendida no ImageNet\n",
        "\n",
        "Para que o modelo seja treinado para o contexto dos nossos dados, excluímos as últimas camadas totalmente conectadas do VGG16, adicionando novas camadas para serem treinadas. Assim, podemos pensar que estamos apenas usando a rede pré-treinada para extrair características e treinando uma rede mlp nova com essas características.\n",
        "\n",
        "É importante que façamos com que os pesos das camadas extratoras da VGG16 não se alterem durante o treinamento. Apenas as camadas totalmente conectadas que adicionaremos ao modelo é que serão alteradas durante o treinamento.\n",
        "\n",
        "\n",
        "\n",
        "Para treinamento do modelo, usaremos o algoritmo de otimização ADAM, com a função objetiva como a entropia cruzada categórica. Nossa principal métrica de desempenho será a acurácia."
      ],
      "metadata": {
        "id": "L6qv-wkKZL3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregamos o modelo VGG16 sem as últimas camadas totalmente conectadas (include_top=False)\n",
        "pre_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "newInput = Input(batch_shape=(None, 32, 32, 3))\n",
        "resizedImg = Lambda(lambda image: tf.compat.v1.image.resize_images(image, (224, 224)))(newInput)\n",
        "newOutputs = pre_model(resizedImg)\n",
        "pre_model = Model(newInput, newOutputs)\n",
        "\n",
        "# Aqui fazemos com que as camadas do modelo pré-treinado não sejam alteradas durante o treino\n",
        "for layer in pre_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "# Criamos então um modelo sequential onde temos o VGG16 seguido das novas camadas conectadas\n",
        "def define_model():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(pre_model)\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(512, activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  opt = Adam(learning_rate=0.001)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "suXiZFlbAmmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# descrição do modelo\n",
        "model = define_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRrpgqvcQ5_i",
        "outputId": "f82390ed-c0b1-405f-f5d4-e59ee0a0923b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " model_1 (Functional)        (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 512)               12845568  \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27,694,154\n",
            "Trainable params: 12,979,466\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV4AHx5FuDV8",
        "outputId": "a7480959-2950-40f2-c23c-f41dbe5c853c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 198s 126ms/step - loss: 1.3976 - accuracy: 0.5005\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 194s 124ms/step - loss: 1.1305 - accuracy: 0.5944\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 194s 124ms/step - loss: 1.0364 - accuracy: 0.6284\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 194s 124ms/step - loss: 0.9809 - accuracy: 0.6487\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 194s 124ms/step - loss: 0.9324 - accuracy: 0.6663\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 194s 124ms/step - loss: 0.9054 - accuracy: 0.6777\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 194s 124ms/step - loss: 0.8767 - accuracy: 0.6875\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 193s 124ms/step - loss: 0.8794 - accuracy: 0.6863\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 194s 124ms/step - loss: 0.8759 - accuracy: 0.6894\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 193s 124ms/step - loss: 0.8199 - accuracy: 0.7089\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7a93246f8fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Avaliação do modelo com o conjunto de teste\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "l9igZ8M4bPof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, Y_test)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "DkNVBAsouSJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62965695-79af-4a08-bb42-06fb7504a51c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 39s 123ms/step - loss: 0.8319 - accuracy: 0.7151\n",
            "Test loss: 0.831900954246521\n",
            "Test accuracy: 0.7150999903678894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregamos o modelo VGG16 sem as últimas camadas totalmente conectadas (include_top=False)\n",
        "model = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
        "\n",
        "newInput = Input(batch_shape=(None, 32, 32, 3))\n",
        "resizedImg = Lambda(lambda image: tf.compat.v1.image.resize_images(image, (48, 48)))(newInput)\n",
        "newOutputs = model(resizedImg)\n",
        "model = Model(newInput, newOutputs)\n",
        "\n",
        "# Aqui fazemos com que as camadas do modelo pré-treinado não sejam alteradas durante o treino\n",
        "for layer in pre_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "# Add the same dense layers as in VGG16\n",
        "output = model.output\n",
        "output = Flatten()(output)\n",
        "output = Dense(units=512, activation='relu')(output)\n",
        "output = Dense(units=256, activation='relu')(output)\n",
        "output = Dense(units=10, activation='softmax')(output)\n",
        "model = Model(model.input, output)\n"
      ],
      "metadata": {
        "id": "9vpThB7D9Y0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cj3Mdg2-egG",
        "outputId": "b88e506f-d8eb-47d9-b41e-2b3e036743a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_19 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " lambda_11 (Lambda)          (None, 48, 48, 3)         0         \n",
            "                                                                 \n",
            " vgg16 (Functional)          (None, 1, 1, 512)         14714688  \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,111,242\n",
            "Trainable params: 15,111,242\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "qHJDV2Z9-RtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TY2_ea7wAxtb",
        "outputId": "2681b080-0d10-4096-da3c-a466635caf4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 60s 38ms/step - loss: 1.7868 - accuracy: 0.2901\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 59s 38ms/step - loss: 1.3515 - accuracy: 0.4831\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 61s 39ms/step - loss: 1.0906 - accuracy: 0.6075\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 61s 39ms/step - loss: 0.9398 - accuracy: 0.6688\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 60s 39ms/step - loss: 0.8270 - accuracy: 0.7127\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 60s 38ms/step - loss: 0.7443 - accuracy: 0.7471\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 59s 38ms/step - loss: 0.6889 - accuracy: 0.7676\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 60s 38ms/step - loss: 0.6190 - accuracy: 0.7936\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 59s 38ms/step - loss: 0.5874 - accuracy: 0.8046\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 60s 38ms/step - loss: 0.5313 - accuracy: 0.8256\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7a940e370e50>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, Y_test)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt03U4lpDpru",
        "outputId": "fbb656b9-a5c2-4e37-f1c5-906e92a99d0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 4s 12ms/step - loss: 0.7489 - accuracy: 0.7661\n",
            "Test loss: 0.7489198446273804\n",
            "Test accuracy: 0.7660999894142151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "This script has the method\n",
        "preprocess_data(X, Y):\n",
        "\"\"\"\n",
        "import tensorflow.keras as K\n",
        "\n",
        "\n",
        "def preprocess_data(X, Y):\n",
        "        \"\"\" This method has the preprocess to train a model \"\"\"\n",
        "        X = X.astype('float32')\n",
        "        X_p = K.applications.vgg16.preprocess_input(X)\n",
        "        Y_p = K.utils.to_categorical(Y, 10)\n",
        "        return(X_p, Y_p)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    (Xt, Yt), (X, Y) = K.datasets.cifar10.load_data()\n",
        "    X_p, Y_p = preprocess_data(Xt, Yt)\n",
        "    Xv_p, Yv_p = preprocess_data(X, Y)\n",
        "    base_model = K.applications.vgg16.VGG16(include_top=False,\n",
        "                                            weights='imagenet',\n",
        "                                            pooling='avg'\n",
        "                                            )\n",
        "\n",
        "    model= K.Sequential()\n",
        "    model.add(K.layers.UpSampling2D())\n",
        "    model.add(base_model)\n",
        "    model.add(K.layers.Flatten())\n",
        "    model.add(K.layers.Dense(512, activation=('relu')))\n",
        "    model.add(K.layers.Dropout(0.2))\n",
        "    model.add(K.layers.Dense(256, activation=('relu')))\n",
        "    model.add(K.layers.Dropout(0.2))\n",
        "    model.add(K.layers.Dense(10, activation=('softmax')))\n",
        "    callback = []\n",
        "    def decay(epoch):\n",
        "        \"\"\" This method create the alpha\"\"\"\n",
        "        return 0.001 / (1 + 1 * 30)\n",
        "    callback += [K.callbacks.LearningRateScheduler(decay, verbose=1)]\n",
        "    callback += [K.callbacks.ModelCheckpoint('cifar10.h5',\n",
        "                                             save_best_only=True,\n",
        "                                             mode='min'\n",
        "                                             )]\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    model.fit(x=X_p, y=Y_p,\n",
        "              batch_size=128,\n",
        "              validation_data=(Xv_p, Yv_p),\n",
        "              epochs=10, shuffle=True,\n",
        "              callbacks=callback,\n",
        "              verbose=1\n",
        "              )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVLHWVwMEcw_",
        "outputId": "057ee3c5-093d-49db-b225-982dd51d6249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 1/10\n",
            "391/391 [==============================] - 91s 201ms/step - loss: 1.3837 - accuracy: 0.5350 - val_loss: 0.6017 - val_accuracy: 0.7987 - lr: 3.2258e-05\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 77s 196ms/step - loss: 0.5351 - accuracy: 0.8261 - val_loss: 0.4378 - val_accuracy: 0.8580 - lr: 3.2258e-05\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 78s 200ms/step - loss: 0.3500 - accuracy: 0.8875 - val_loss: 0.3623 - val_accuracy: 0.8839 - lr: 3.2258e-05\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 80s 204ms/step - loss: 0.2309 - accuracy: 0.9241 - val_loss: 0.3567 - val_accuracy: 0.8896 - lr: 3.2258e-05\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 78s 200ms/step - loss: 0.1631 - accuracy: 0.9464 - val_loss: 0.3281 - val_accuracy: 0.9038 - lr: 3.2258e-05\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 60s 153ms/step - loss: 0.1068 - accuracy: 0.9647 - val_loss: 0.3640 - val_accuracy: 0.8935 - lr: 3.2258e-05\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 60s 152ms/step - loss: 0.0782 - accuracy: 0.9750 - val_loss: 0.4038 - val_accuracy: 0.9027 - lr: 3.2258e-05\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 58s 148ms/step - loss: 0.0575 - accuracy: 0.9817 - val_loss: 0.4145 - val_accuracy: 0.9013 - lr: 3.2258e-05\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 60s 153ms/step - loss: 0.0451 - accuracy: 0.9851 - val_loss: 0.3854 - val_accuracy: 0.9083 - lr: 3.2258e-05\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 58s 148ms/step - loss: 0.0376 - accuracy: 0.9884 - val_loss: 0.4397 - val_accuracy: 0.9096 - lr: 3.2258e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_p, Y_p)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HLZlaRNJx3i",
        "outputId": "9e756b9f-06c9-4a14-85e8-03e5b76cb0ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1563/1563 [==============================] - 23s 15ms/step - loss: 0.0242 - accuracy: 0.9924\n",
            "Test loss: 0.024182196706533432\n",
            "Test accuracy: 0.9923999905586243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "tf.keras.layers.InputLayer(input_shape=(32, 32, 3)),\n",
        "tf.keras.layers.UpSampling2D(size = (2,2)),\n",
        "tf.keras.layers.UpSampling2D(size = (2,2)),\n",
        "tf.keras.layers.UpSampling2D(size = (2,2)),\n",
        "base_model,\n",
        "tf.keras.layers.Flatten(),\n",
        "tf.keras.layers.Dense(512, activation='relu'),\n",
        "tf.keras.layers.Dense(256, activation='relu'),\n",
        "tf.keras.layers.Dropout(0.3),\n",
        "tf.keras.layers.Dense(128, activation='relu'),\n",
        "tf.keras.layers.Dense(10, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "55s7ZODTNagA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-DPOtOyRj80",
        "outputId": "a785e488-d6db-4d6b-b07a-a3381316df48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " up_sampling2d_16 (UpSamplin  (None, 64, 64, 3)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " up_sampling2d_17 (UpSamplin  (None, 128, 128, 3)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " up_sampling2d_18 (UpSamplin  (None, 256, 256, 3)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " vgg16 (Functional)          (None, 8, 8, 512)         14714688  \n",
            "                                                                 \n",
            " flatten_17 (Flatten)        (None, 32768)             0         \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 512)               16777728  \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_60 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,657,930\n",
            "Trainable params: 16,943,242\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "kR2yZH9zRzIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1sDOm8xR70Y",
        "outputId": "bbb48f11-209b-4fd3-cc17-82760dc03ccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 253s 158ms/step - loss: 1.3098 - accuracy: 0.5384\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 244s 156ms/step - loss: 0.9805 - accuracy: 0.6570\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 244s 156ms/step - loss: 0.8792 - accuracy: 0.6965\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 244s 156ms/step - loss: 0.8105 - accuracy: 0.7203\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 243s 156ms/step - loss: 0.7515 - accuracy: 0.7400\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 243s 156ms/step - loss: 0.7122 - accuracy: 0.7555\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 244s 156ms/step - loss: 0.6747 - accuracy: 0.7676\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 244s 156ms/step - loss: 0.6282 - accuracy: 0.7820\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 244s 156ms/step - loss: 0.6030 - accuracy: 0.7926\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 244s 156ms/step - loss: 0.5678 - accuracy: 0.8029\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7a93246fa350>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, Y_test)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NizoINO-R0C0",
        "outputId": "c0c3a846-317c-4e3a-8c72-b244d63db8fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 49s 155ms/step - loss: 0.8484 - accuracy: 0.7257\n",
            "Test loss: 0.8484376072883606\n",
            "Test accuracy: 0.7257000207901001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "tf.keras.layers.InputLayer(input_shape=(32, 32, 3)),\n",
        "tf.keras.layers.UpSampling2D(size = (2,2)),\n",
        "tf.keras.layers.UpSampling2D(size = (2,2)),\n",
        "tf.keras.layers.UpSampling2D(size = (2,2)),\n",
        "base_model,\n",
        "tf.keras.layers.Flatten(),\n",
        "tf.keras.layers.Dense(512, activation='relu'),\n",
        "tf.keras.layers.Dense(256, activation='relu'),\n",
        "tf.keras.layers.Dropout(0.3),\n",
        "tf.keras.layers.Dense(128, activation='relu'),\n",
        "tf.keras.layers.Dense(10, activation='softmax')])\n",
        "\n",
        "callback = []\n",
        "def decay(epoch):\n",
        "        \"\"\" This method create the alpha\"\"\"\n",
        "        return 0.001 / (1 + 1 * 30)\n",
        "callback += [K.callbacks.LearningRateScheduler(decay, verbose=1)]\n",
        "callback += [K.callbacks.ModelCheckpoint('cifar10.h5',\n",
        "                                             save_best_only=True,\n",
        "                                             mode='min'\n",
        "                                             )]\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "j1m9zFXWcycd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iw4psnmRdvQs",
        "outputId": "65e89b9d-4b98-4c13-a04b-b5ed551977dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " up_sampling2d_19 (UpSamplin  (None, 64, 64, 3)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " up_sampling2d_20 (UpSamplin  (None, 128, 128, 3)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " up_sampling2d_21 (UpSamplin  (None, 256, 256, 3)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " vgg16 (Functional)          (None, 8, 8, 512)         14714688  \n",
            "                                                                 \n",
            " flatten_18 (Flatten)        (None, 32768)             0         \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 512)               16777728  \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_63 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_64 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,657,930\n",
            "Trainable params: 16,943,242\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,\n",
        "          Y_train,\n",
        "          epochs=10, shuffle=True,\n",
        "          callbacks=callback,\n",
        "          batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgHYz_ggdKke",
        "outputId": "8f780103-1198-4cba-c303-99619c32cb81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 248s 158ms/step - loss: 1.4224 - accuracy: 0.5029 - lr: 3.2258e-05\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 247s 158ms/step - loss: 1.0556 - accuracy: 0.6364 - lr: 3.2258e-05\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 247s 158ms/step - loss: 0.9323 - accuracy: 0.6776 - lr: 3.2258e-05\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 246s 158ms/step - loss: 0.8535 - accuracy: 0.7048 - lr: 3.2258e-05\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 246s 157ms/step - loss: 0.7971 - accuracy: 0.7237 - lr: 3.2258e-05\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 247s 158ms/step - loss: 0.7469 - accuracy: 0.7422 - lr: 3.2258e-05\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 247s 158ms/step - loss: 0.7035 - accuracy: 0.7554 - lr: 3.2258e-05\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 246s 158ms/step - loss: 0.6666 - accuracy: 0.7690 - lr: 3.2258e-05\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 247s 158ms/step - loss: 0.6282 - accuracy: 0.7823 - lr: 3.2258e-05\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 247s 158ms/step - loss: 0.5983 - accuracy: 0.7941 - lr: 3.2258e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7a940d7b04c0>"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, Y_test)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zI2I9yfqnyuU",
        "outputId": "2bada7bc-b4df-4f0f-beee-6d48303dceae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 49s 156ms/step - loss: 0.7788 - accuracy: 0.7319\n",
            "Test loss: 0.7787634134292603\n",
            "Test accuracy: 0.7318999767303467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "This script has the method\n",
        "preprocess_data(X, Y):\n",
        "\"\"\"\n",
        "import tensorflow.keras as K\n",
        "\n",
        "\n",
        "def preprocess_data(X, Y):\n",
        "        \"\"\" This method has the preprocess to train a model \"\"\"\n",
        "        X = X.astype('float32')\n",
        "        X_p = K.applications.vgg16.preprocess_input(X)\n",
        "        Y_p = K.utils.to_categorical(Y, 10)\n",
        "        return(X_p, Y_p)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    (Xt, Yt), (X, Y) = K.datasets.cifar10.load_data()\n",
        "    assert Xt.shape == (50000, 32, 32, 3)\n",
        "    assert X.shape == (10000, 32, 32, 3)\n",
        "    assert Yt.shape == (50000, 1)\n",
        "    assert Y.shape == (10000, 1)\n",
        "\n",
        "    X_p, Y_p = preprocess_data(Xt, Yt)\n",
        "    Xv_p, Yv_p = preprocess_data(X, Y)\n",
        "    base_model = K.applications.vgg16.VGG16(include_top=False,\n",
        "                                            weights='imagenet',\n",
        "                                            pooling='avg'\n",
        "                                            )\n",
        "\n",
        "    model= K.Sequential()\n",
        "    model.add(K.layers.UpSampling2D())\n",
        "    model.add(base_model)\n",
        "    model.add(K.layers.Flatten())\n",
        "    model.add(K.layers.Dense(512, activation=('relu')))\n",
        "    model.add(K.layers.Dropout(0.2))\n",
        "    model.add(K.layers.Dense(256, activation=('relu')))\n",
        "    model.add(K.layers.Dropout(0.2))\n",
        "    model.add(K.layers.Dense(10, activation=('softmax')))\n",
        "    callback = []\n",
        "    def decay(epoch):\n",
        "        \"\"\" This method create the alpha\"\"\"\n",
        "        return 0.001 / (1 + 1 * 30)\n",
        "    callback += [K.callbacks.LearningRateScheduler(decay, verbose=1)]\n",
        "    callback += [K.callbacks.ModelCheckpoint('cifar10.h5',\n",
        "                                             save_best_only=True,\n",
        "                                             mode='min'\n",
        "                                             )]\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    model.fit(x=X_p, y=Y_p,\n",
        "              batch_size=128,\n",
        "              validation_data=(Xv_p, Yv_p),\n",
        "              epochs=10, shuffle=True,\n",
        "              callbacks=callback,\n",
        "              verbose=1\n",
        "              )\n",
        "\n",
        "    predicted_x = model.predict(Xv_p)\n",
        "    residuals = np.argmax(predicted_x,1)!=np.argmax(Yv_p,1)\n",
        "\n",
        "    loss = sum(residuals)/len(residuals)\n",
        "    print(\"the validation 0/1 loss is: \",loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8-miq1Ix_vf",
        "outputId": "1baa9474-41fe-4d2d-ad1a-d6e5589f537f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 1/10\n",
            "391/391 [==============================] - 73s 169ms/step - loss: 1.4178 - accuracy: 0.5241 - val_loss: 0.6176 - val_accuracy: 0.7979 - lr: 3.2258e-05\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 63s 161ms/step - loss: 0.5275 - accuracy: 0.8298 - val_loss: 0.4005 - val_accuracy: 0.8703 - lr: 3.2258e-05\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 63s 161ms/step - loss: 0.3363 - accuracy: 0.8909 - val_loss: 0.3411 - val_accuracy: 0.8897 - lr: 3.2258e-05\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 63s 160ms/step - loss: 0.2267 - accuracy: 0.9254 - val_loss: 0.3145 - val_accuracy: 0.9021 - lr: 3.2258e-05\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 57s 147ms/step - loss: 0.1594 - accuracy: 0.9475 - val_loss: 0.3510 - val_accuracy: 0.9013 - lr: 3.2258e-05\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 59s 152ms/step - loss: 0.1011 - accuracy: 0.9662 - val_loss: 0.3243 - val_accuracy: 0.9057 - lr: 3.2258e-05\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 59s 152ms/step - loss: 0.0713 - accuracy: 0.9769 - val_loss: 0.4180 - val_accuracy: 0.8973 - lr: 3.2258e-05\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 59s 152ms/step - loss: 0.0524 - accuracy: 0.9824 - val_loss: 0.3667 - val_accuracy: 0.9121 - lr: 3.2258e-05\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 59s 152ms/step - loss: 0.0471 - accuracy: 0.9855 - val_loss: 0.3555 - val_accuracy: 0.9134 - lr: 3.2258e-05\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 59s 152ms/step - loss: 0.0411 - accuracy: 0.9869 - val_loss: 0.4336 - val_accuracy: 0.9047 - lr: 3.2258e-05\n",
            "313/313 [==============================] - 4s 13ms/step\n",
            "the validation 0/1 loss is:  0.0953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(Xv_p, Yv_p)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poXPA8Gv4UTC",
        "outputId": "a3d763e9-edb1-4cfe-ac32-c5237a000a2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 5s 15ms/step - loss: 0.4336 - accuracy: 0.9047\n",
            "Test loss: 0.43364930152893066\n",
            "Test accuracy: 0.904699981212616\n"
          ]
        }
      ]
    }
  ]
}